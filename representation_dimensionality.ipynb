{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a34251f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/fstella/felix/anaconda3/lib/python3.11/site-packages/matplotlib/mpl-data/matplotlibrc\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from neuron import PyramidalCells\n",
    "from sklearn.decomposition import PCA\n",
    "from itertools import product\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "526b405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_firing_rates(pyramidal, event_count, x_run):\n",
    "\n",
    "    print('Event count shape:', event_count.shape)\n",
    "    firing_rates = np.zeros((event_count.shape[1], 1024))\n",
    "    x_run_reshaped = np.zeros(1024)\n",
    "    step_size = len(event_count)//firing_rates.shape[1]\n",
    "    \n",
    "    for i in range(firing_rates.shape[1]):\n",
    "        firing_rates[:, i] = np.sum(event_count[i * step_size:(i + 1) * step_size, :], axis = 0) / (step_size*pyramidal.dt)\n",
    "        x_run_reshaped[i] = np.mean(x_run[i * step_size:(i + 1) * step_size])\n",
    "\n",
    "    return firing_rates, x_run_reshaped\n",
    "\n",
    "\n",
    "def get_activation_map(firing_rates, m_EC, x_run_reshaped, n_bins = 64):\n",
    "    sort_TD = np.argsort(m_EC)\n",
    "    sorted_fr = firing_rates[np.ix_(sort_TD, np.arange(firing_rates.shape[1]))]\n",
    "\n",
    "    bins = np.arange(n_bins)\n",
    "    n_cell = np.arange(sorted_fr.shape[0])\n",
    "    out_collector = {k : [] for k in product(n_cell, bins)}\n",
    "    out = np.zeros((sorted_fr.shape[0], n_bins))\n",
    "    position_bins = np.linspace(0, x_run_reshaped.max(), n_bins)\n",
    "\n",
    "    for idx, pos in enumerate(x_run_reshaped):\n",
    "        bin_idx = np.argmin(np.abs(position_bins - pos))\n",
    "\n",
    "        for i in range(sorted_fr.shape[0]):\n",
    "            out_collector[(i, bin_idx)].append(sorted_fr[i, idx])\n",
    "\n",
    "    for k, v in out_collector.items():\n",
    "        out[k] = np.mean(v)\n",
    "\n",
    "    return out\n",
    "\n",
    "def simulate_run(len_track = 200, av_running_speed = 20, dt = 0.01, tn = 1000):\n",
    "    ## TODO: Does it need to be this long?\n",
    "    bins = np.arange(0., len_track)\n",
    "    fps = 1/dt\n",
    "    n_runs = int(2*tn/(len_track/av_running_speed))\n",
    "\n",
    "    x = np.array([])\n",
    "    i = 0\n",
    "    while True:\n",
    "        stopping_time = np.random.uniform(0, 1, 2)\n",
    "        stop1 = np.ones((int(stopping_time[0]*fps),)) * 0.\n",
    "        speed = av_running_speed + np.random.randn() * 5\n",
    "        run_length = len(bins) * fps / speed\n",
    "        run1 = np.linspace(0., float(len(bins)-1), int(run_length))\n",
    "        stop2 = np.ones((int(stopping_time[1]*fps),)) * (len(bins)-1.)\n",
    "        speed = av_running_speed + np.random.randn() * 5\n",
    "        run_length = len(bins) * fps / speed\n",
    "        run2 = np.linspace(len(bins)-1., 0., int(run_length))\n",
    "        x = np.concatenate((x, stop1, run1, stop2, run2))\n",
    "        if len(x) >= tn*fps:\n",
    "            break\n",
    "        i += 1\n",
    "\n",
    "    x = x[:int(tn*fps)]\n",
    "    t = np.arange(len(x))/fps\n",
    "\n",
    "    return t, x\n",
    "\n",
    "\n",
    "def smooth(x, window_len=11, window='hanning'):\n",
    "    \"\"\"\n",
    "    Smooth the data using a window with requested size.\n",
    "    \n",
    "    Inputs:\n",
    "        x: Input signal \n",
    "        window_len: Dimension of the smoothing window; should be an odd integer\n",
    "        window: Window type from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\n",
    "            flat window will produce a moving average smoothing.\n",
    "\n",
    "    Outputs:\n",
    "       y: Smoothed signal\n",
    "    \"\"\"\n",
    "\n",
    "    if window_len<3:\n",
    "        return x\n",
    "\n",
    "    s = np.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n",
    "\n",
    "    if window=='flat': #moving average\n",
    "        w = np.ones(window_len,'d')\n",
    "    else:\n",
    "        w = eval('np.'+window+'(window_len)')\n",
    "\n",
    "    y = np.convolve(w/w.sum(),s,mode='valid')\n",
    "    return y\n",
    "\n",
    "\n",
    "def intrinsic_dimensionality(points, nstep=10, metric='euclidean', dist_mat=None, ds=1,\\\n",
    "                              plot=1, verbose=0, offset_min=10, win_smooth=7, fit='std',\\\n",
    "                              thr_start=10, thr_fi=1e5):\n",
    "    '''\n",
    "    Obtain the intrinsic dimensionality of a point cloud / neural population activity\n",
    "    by using exponent (slope on log-log plot) ofcumulative neighbours (NN) distrubution\n",
    "    to estimate intrinsic dimensionality\n",
    "\n",
    "    Inputs:\n",
    "         points: NxT point cloud\n",
    "         n_step: n of distance step to evaluate\n",
    "         metric: which metric to use to obtain the distance matrix\n",
    "         dist_mat: if 'precomputed', consider `points` as a distance matrix\n",
    "         ds: downsampling factor\n",
    "         plot: visualise curve (boolean)\n",
    "         verbose: print feedback on code progression\n",
    "         fit: how to estimate dimewnsionality\n",
    "           - 'std': use `thr_start` and `thr_fi` to select NN range where to fit exponential\n",
    "           - 'all': use the full NN range\n",
    "           - 'diff': find the linear part of the curve (using 2nd diff) and fit line to it\n",
    "                       (start at offset min at least; `win_smooth` is smoothing parameter to estimate\n",
    "                        min and max of the 2nd diff)\n",
    "                        \n",
    "     Outputs:\n",
    "         Nneigh: number of neighbours found per point at every radii\n",
    "         radii: radii steps used\n",
    "         p: linear fit in log-log axes\n",
    "         \n",
    "    Faster than using KD tree\n",
    "    '''\n",
    "\n",
    "    from sklearn.metrics.pairwise import euclidean_distances, cosine_distances\n",
    "    \n",
    "    Nneigh = np.zeros((points.shape[0],nstep))\n",
    "    if dist_mat=='precomputed':\n",
    "        dist_mat = points\n",
    "    else: # compute distance matrix\n",
    "        # Find diameter of point cloud\n",
    "        points[np.isnan(points)] = 0\n",
    "        if metric=='euclidean': dist_mat = euclidean_distances(points)\n",
    "        elif metric=='cosine': dist_mat = cosine_distances(points)\n",
    "    dist_mat[dist_mat==0] = np.nan\n",
    "    minD = np.nanmin(dist_mat)\n",
    "    maxD = np.nanmax(dist_mat)\n",
    "    \n",
    "    # Define distances to evaluate\n",
    "    radii = np.logspace(np.log10(minD), np.log10(maxD), nstep)\n",
    "    # Fing #neigh vs dist\n",
    "    for n,rad in enumerate(radii):\n",
    "        Nneigh[:,n] = np.sum((dist_mat<rad), 1)\n",
    "        if verbose: print(f'{n+1}/{len(radii)}')\n",
    "    \n",
    "    # find slope of neighbors increase = dimensionality\n",
    "    sem = np.std(Nneigh,0)\n",
    "    mean_ = np.mean(Nneigh,0)\n",
    "    sem_ = np.log10(sem[1:])\n",
    "    x2p = radii[1:]; y2p = mean_[1:]\n",
    "    x2p = x2p / np.max(x2p) # normalise the distance radii\n",
    "    \n",
    "    # find indeces where curve is linear for fit\n",
    "    if fit=='std': # fit line from #thr_start NN until #thre_fi NN\n",
    "        start = np.argmin(np.abs(mean_ - thr_start))\n",
    "        fi = np.argmin(np.abs(mean_ - thr_fi))\n",
    "    elif fit=='diff': # find linear part of the curve using 2nd diff\n",
    "        diff2nd = np.diff(np.diff(smooth(np.log10(y2p), window_len=win_smooth)))\n",
    "        fi = np.argmin(diff2nd[offset_min:])+offset_min\n",
    "        start = np.argmax(diff2nd[:fi])\n",
    "    elif fit=='all': # use all data\n",
    "        start = 0\n",
    "        fi = len(mean_)-1\n",
    "        \n",
    "    # line fit\n",
    "    x2fit = x2p[start:fi]\n",
    "    y2fit = y2p[start:fi]\n",
    "    p = np.polyfit(np.log10(x2fit), np.log10(y2fit), deg=1)\n",
    "    \n",
    "    # plot\n",
    "    if plot:\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.plot(x2p, y2p) # og data\n",
    "        y_mod = 10**p[1] * np.power(x2fit, p[0]) # best fit power law\n",
    "        plt.plot(x2fit, y_mod, 'r')\n",
    "        plt.xlabel('Distance')\n",
    "        plt.ylabel('# neighbours')\n",
    "        plt.xscale('log')\n",
    "        plt.yscale('log')\n",
    "        plt.title('The dimensionality/slope is %.2f'%p[0])\n",
    "        sns.despine()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "    return Nneigh, radii, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be8cdc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t_epoch = 1\n",
    "speed = 20\n",
    "len_track = 100. \n",
    "dt = 0.001\n",
    "tn = len_track/speed*32\n",
    "a = 0.3\n",
    "n_cells = {'pyramidal' : 200, 'inter_a' : 20, 'inter_b' : 20, 'CA3' : 120}\n",
    "len_track = 100\n",
    "n_env = 50\n",
    "a = 0 ## Similarity between maps\n",
    "lr = 15\n",
    "n_bins = 100\n",
    "\n",
    "\n",
    "DIMS = 5\n",
    "nstep = 30 # TODO: what does this do?\n",
    "\n",
    "t_run, x_run = simulate_run(len_track=len_track, av_running_speed=speed, dt=dt, tn=tn)\n",
    "x_pos = np.arange(0, len_track, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e53ae7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'plots/measure_representation/all_envs_CA1_al_0_0.0.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m all_env_CA1_alphas \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m al \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.05\u001b[39m]:\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplots/measure_representation/all_envs_CA1_al_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mal\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ma\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     13\u001b[0m         all_envs_CA1_al \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     15\u001b[0m     all_env_CA1_alphas[al] \u001b[38;5;241m=\u001b[39m all_envs_CA1_al\n",
      "File \u001b[0;32m/scratch/fstella/felix/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'plots/measure_representation/all_envs_CA1_al_0_0.0.pkl'"
     ]
    }
   ],
   "source": [
    "\n",
    "all_n_dims = {}\n",
    "\n",
    "for a in np.round(np.linspace(0,1,11),1):\n",
    "    with open(f'plots/measure_representation/all_envs_{a}.pkl', 'rb') as f:\n",
    "        all_envs_CA3, all_envs_CA1 = pickle.load(f)\n",
    "    with open(f'plots/measure_representation/all_envs_no_EC_{a}.pkl', 'rb') as f:\n",
    "        all_envs_CA1_no_EC = pickle.load(f)\n",
    "\n",
    "    all_env_CA1_alphas = {}\n",
    "\n",
    "    for al in [0, 0.01, 0.05]:\n",
    "        with open(f'plots/measure_representation/all_envs_{al}_{a}.pkl', 'rb') as f:\n",
    "            all_envs_CA1_al = pickle.load(f)\n",
    "        \n",
    "        all_env_CA1_alphas[al] = all_envs_CA1_al\n",
    "        \n",
    "\n",
    "\n",
    "    random = np.random.rand(n_env*x_pos.shape[0], n_cells['CA3'])\n",
    "    n_dims = {'CA3': [], \n",
    "              'CA1': [], \n",
    "              'CA1_no_EC': [],\n",
    "              'CA1_al_0': [],\n",
    "              'CA1_al_0.01': [],\n",
    "              'CA1_al_0.05': [],\n",
    "              'random': []}\n",
    "\n",
    "    for env_idx in tqdm(range(n_env)):\n",
    "\n",
    "        for area, X in {\n",
    "            'CA1': all_envs_CA1[:(env_idx+1)*n_bins, :], \n",
    "            'CA1_no_EC': all_envs_CA1_no_EC[:(env_idx+1)*n_bins, :],\n",
    "            'CA3': all_envs_CA3[:(env_idx+1)*x_pos.shape[0], :],\n",
    "            'CA1_al_0': all_env_CA1_alphas[0][:(env_idx+1)*n_bins, :],\n",
    "            'CA1_al_0.01': all_env_CA1_alphas[0.01][:(env_idx+1)*n_bins, :],\n",
    "            'CA1_al_0.05': all_env_CA1_alphas[0.05][:(env_idx+1)*n_bins, :],\n",
    "            'random': random[:(env_idx+1)*x_pos.shape[0], :]\n",
    "            }.items():\n",
    "            \n",
    "            pca = PCA(n_components=DIMS)\n",
    "            x_embd = pca.fit_transform(X)\n",
    "            x_embd = x_embd / np.max(np.abs(x_embd)) # normalise the values\n",
    "            AXIS_LIM = np.max(x_embd)\n",
    "        \n",
    "            Nneigh, radii, p = intrinsic_dimensionality(x_embd, nstep=nstep, metric='euclidean',\n",
    "                                                        fit='std', thr_start=10, thr_fi=5e3, plot=False)\n",
    "            \n",
    "            n_dims[area].append(p[0])\n",
    "        \n",
    "    all_n_dims[a] = n_dims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a88238f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_dims' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcm\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcm\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmcolors\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m area \u001b[38;5;129;01min\u001b[39;00m n_dims\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      7\u001b[0m     fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m      8\u001b[0m     norm \u001b[38;5;241m=\u001b[39m mcolors\u001b[38;5;241m.\u001b[39mNormalize(vmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmin\u001b[39m(all_n_dims\u001b[38;5;241m.\u001b[39mkeys()), vmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(all_n_dims\u001b[38;5;241m.\u001b[39mkeys()))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_dims' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "for area in n_dims.keys():\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    norm = mcolors.Normalize(vmin=min(all_n_dims.keys()), vmax=max(all_n_dims.keys()))\n",
    "    colormap = cm.viridis\n",
    "    for a in all_n_dims.keys():\n",
    "        if a == 1.0:\n",
    "            continue\n",
    "        n_dims = all_n_dims[a]\n",
    "        ax.plot(np.arange(1, len(n_dims[area]) + 1), n_dims[area], color=colormap(norm(a)), label=f'{a:.1f}')\n",
    "    \n",
    "    sm = cm.ScalarMappable(cmap=colormap, norm=norm)\n",
    "    sm.set_array([])  # Dummy array so ScalarMappable is valid\n",
    "    cbar = fig.colorbar(sm, ax=ax)  # <--- pass ax here!\n",
    "    cbar.set_label('a')\n",
    "\n",
    "    ax.set_xlabel('No. of Environments')\n",
    "    ax.set_ylabel('Intrinsic Dimensionality')\n",
    "    ax.set_title(area)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac206f79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
